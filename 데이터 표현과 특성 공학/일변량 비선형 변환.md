## 일변량 비선형 변환

- log, exp, sin 같은 수학 함수를 적용하는 방법도 특성 변환에 유용
- 트리 기반 모델은 특성의 순서에만 영향을 받지만 선형 모델과 신경망은 각 특성의 스케일과 분포에 밀접한 연관이 있음
  - 트리 기반 모델의 max_feature 매개변수는 트리의 각 분기에서 사용될 후보 특성의 개수를 제한 (특성의 나열 순서가 결과에 영향을 줄 수 있음)
- 대부분의 모델은 각 특성이 정규분포와 비슷할 때 최고의 성능을 냄
- log, exp 같은 함수를 사용해서 이러한 분포를 효과적으로 만들 수 있음
  - 정수 카운트 데이터를 다룰때 이러한 변환이 도움이 됨 **(음수가 없으며 특별한 통계 패턴을 따르는 경우가 많음)**

```python
import numpy as np
import matplotlib.pyplot as plt

rnd = np.random.RandomState(0)
X_org = rnd.normal(size=(1000, 3))
w = rnd.normal(size=3)

X = rnd.poisson(10 * np.exp(X_org))
y = np.dot(X_org, w)

print("특성 출현 횟수:\n", np.bincount(X[:, 0]))
# 특성 출현 횟수:
# [28 38 68 48 61 59 45 56 37 40 35 34 36 26 23 26 27 21 23 23 18 21 10  9 17  9  7 14 12  7  3  8  4  5  5  3  4  2  4  1  1  3  2  5  3  8  2  5 2  1  2  3  3  2  2  3  3  0  1  2  1  0  0  3  1  0  0  0  1  3  0  1 0  2  0  1  1  0  0  0  0  1  0  0  2  2  0  1  1  0  0  0  0  1  1  0 0  0  0  0  0  0  1  0  0  0  0  0  1  1  0  0  1  0  0  0  0  0  0  0 1  0  0  0  0  1  0  0  0  0  0  0  0  0  0  0  0  0  0  0  1]

plt.rc('font', family="Malgun Gothic")
plt.bar(range(len(np.bincount(X[:, 0]))), np.bincount(X[:, 0]))
plt.ylabel("특성 출현 횟수")
plt.xlabel("값")
plt.show()
```

2가 68번으로 가장 많이 나타나고 번호가 올라갈수록 빈도수도 줄어드는 경향

<img src="https://user-images.githubusercontent.com/58063806/113159592-af9d0980-9277-11eb-8bce-736205642aff.png" width=50% />

- 이러한 작은 수치가 많고 큰 수치는 몇 안되는 분포는 실제로 자주 나타남 **(푸아송 분포, 선형 모델은 잘 처리하지 못함)**

```python
from sklearn.linear_model import Ridge
from sklearn.model_selection import train_test_split

X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=0)
score = Ridge().fit(X_train, y_train).score(X_test, y_test)
print("test score: {:.3f}".format(score))
# test score: 0.622
```

비교적 낮은 점수가 나옴 (Ridge는 X, y 관계를 제대로 모델링하지 못함)

**log 함수를 적용**

```python
# log 0을 방지하기 위해 + 1
X_train_log = np.log(X_train + 1)
X_test_log = np.log(X_test + 1)

plt.hist(X_train_log[:, 0], bins=25)
plt.ylabel("특성 출현 횟수")
plt.xlabel("값")
```

<img src="https://user-images.githubusercontent.com/58063806/113160556-9052ac00-9278-11eb-85f0-42cb35010fdc.png" width=50% />

log 스케일로 변환 후에는 데이터의 분포가 덜 치우쳐 있고 이상치가 보이지 않음

```python
score = Ridge().fit(X_train_log, y_train).score(X_test_log, y_test)
print("test score: {:.3f}".format(score))
# test score: 0.875
```

같은 모델을 적용했을때 훨씬 좋은 결과를 도출



***이러한 변환은 트리 기반 모델에서는 불필요하지만 선형 모델에서는 필수적 (가끔 회귀에서는 타깃 변수 y를 변환하는 것이 좋을 때도 있음)***

> 카운트를 예측하는 경우가 전형적인 예시