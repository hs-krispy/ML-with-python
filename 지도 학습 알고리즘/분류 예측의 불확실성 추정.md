## 분류 예측의 불확실성 추정

#### 결정 함수

```python
from sklearn.ensemble import GradientBoostingClassifier
from sklearn.datasets import make_circles
from sklearn.model_selection import train_test_split
import numpy as np

X, y = make_circles(noise=0.25, factor=0.5, random_state=1)
y_named = np.array(["blue", "red"])[y]
X_train, X_test, y_train, y_test = train_test_split(X, y_named, stratify=y, random_state=0)

gbrt = GradientBoostingClassifier(random_state=0)
gbrt.fit(X_train, y_train)

print("X_test.shape:", X_test.shape)
print("결정 함수 결과 형태", gbrt.decision_function(X_test).shape)
print("결정 함수:", gbrt.decision_function(X_test)[:6])

# X_test.shape: (25, 2)
# 결정 함수 결과 형태 (25,)
# 결정 함수: [-2.78470212  3.83151879 -3.72759472 -6.91982126 -3.37153802  3.11452043]
```

decision_function : 데이터 포인트가 양성 클래스인 클래스 1에 속한다고 믿는 정도

```python
greater_zero = (gbrt.decision_function(X_test) > 0).astype(int)
pred = gbrt.classes_[greater_zero]

print("pred는 예측결과와 동일", np.all(pred == gbrt.predict(X_test)))

# pred는 예측결과와 동일 True
```

model의 predict 함수과 결과가 동일한 것을 볼 수 있음

```python
import mglearn
import matplotlib.pyplot as plt

plt.rc('font', family="Malgun Gothic")
plt.rcParams['axes.unicode_minus'] = False

fig, axes = plt.subplots(1, 2, figsize=(13, 5))
mglearn.tools.plot_2d_separator(gbrt, X, ax=axes[0], alpha=.4, fill=True, cm=mglearn.cm2)
scores_image = mglearn.tools.plot_2d_scores(gbrt, X, ax=axes[1], alpha=.4, cm=mglearn.ReBl)

for ax in axes:
    mglearn.discrete_scatter(X_test[:, 0], X_test[:, 1], y_test,  markers='^', ax=ax)
    mglearn.discrete_scatter(X_train[:, 0], X_train[:, 1], y_train,  markers='o', ax=ax)
    ax.set_xlabel("특성 0")
    ax.set_ylabel("특성 1")
cbar = plt.colorbar(scores_image, ax=axes.tolist())
cbar.set_alpha(1)
cbar.draw_all()
axes[0].legend(["테스트 클래스 0", "테스트 클래스 1", "훈련 클래스 0", "훈련 클래스 1"], ncol=4, loc=(.1, 1.1))
```

<img src="https://user-images.githubusercontent.com/58063806/111473990-edc20580-876e-11eb-9928-e4c664ba0d1b.png" width=80% />

예측한 결과에 더해 분류기가 얼마나 확신하는 지를 이용해 추가적인 정보를 얻을 수 있지만 결정 함수 그래프에서 두 클래스 사이의 경계를 구분하기는 어려움



#### 예측 확률

```python
print("확률 값의 형태:", gbrt.predict_proba(X_test).shape)
print("예측 확률:\n", gbrt.predict_proba(X_test)[:6])

# 확률 값의 형태: (25, 2)
# 예측 확률:
# [[9.41843535e-01 5.81564645e-02]
# [2.12167596e-02 9.78783240e-01]
# [9.76514232e-01 2.34857677e-02]
# [9.99012969e-01 9.87031332e-04]
# [9.66803089e-01 3.31969107e-02]
# [4.25122592e-02 9.57487741e-01]]
```

각 클래스의 예측확률을 결과로 반환 (모든 확률의 합은 1이 됨)

위의 예시에서는 분류기가 대부분의 포인트에서 비교적 강하게 확신을 함 (한쪽 클래스의 확률이 매우 우세, **일반적으로 복잡도가 낮은 모델은 예측에 불확실성이 더 많음**) 

이러한 불확실성과 모델의 정확도가 동등하면 모델이 보정(calibration)되었다고 함

> 보정된 모델에서 70%의 확신을 가진 예측은 70%의 정확도를 냄

```python
fig, axes = plt.subplots(1, 2, figsize=(13, 5))
mglearn.tools.plot_2d_separator(gbrt, X, ax=axes[0], alpha=.4, fill=True, cm=mglearn.cm2)
scores_image = mglearn.tools.plot_2d_scores(gbrt, X, ax=axes[1], alpha=.5, cm=mglearn.ReBl, function="predict_proba")

for ax in axes:
    mglearn.discrete_scatter(X_test[:, 0], X_test[:, 1], y_test,  markers='^', ax=ax)
    mglearn.discrete_scatter(X_train[:, 0], X_train[:, 1], y_train,  markers='o', ax=ax)
    ax.set_xlabel("특성 0")
    ax.set_ylabel("특성 1")
cbar = plt.colorbar(scores_image, ax=axes.tolist())
cbar.set_alpha(1)
cbar.draw_all()
axes[0].legend(["테스트 클래스 0", "테스트 클래스 1", "훈련 클래스 0", "훈련 클래스 1"], ncol=4, loc=(.1, 1.1))
```

<img src="https://user-images.githubusercontent.com/58063806/111473876-d2ef9100-876e-11eb-811c-5091237ae462.png" width=80% />

예측 확률에 대한 그래프는 두 클래스 간의 경계를 비교적 잘 구분하는 것을 볼 수 있음

#### 다중 분류에서의 불확실성

```python
from sklearn.datasets import load_iris

iris = load_iris()
X_train, X_test, y_train, y_test = train_test_split(iris.data, iris.target, random_state=42)

gbrt = GradientBoostingClassifier(learning_rate=0.01, random_state=0)
gbrt.fit(X_train, y_train)

print("결정 함수의 결과 형태:", gbrt.decision_function(X_test).shape)
print("결정 함수 결과:\n", gbrt.decision_function(X_test)[:6])
print("가장 큰 결정 함수의 인덱스:\n", np.argmax(gbrt.decision_function(X_test), axis=1))
print("예측:\n", gbrt.predict(X_test))

# 결정 함수의 결과 형태: (38, 3)
# 결정 함수 결과:
# [[-1.9957153   0.04758118 -1.92721297]
# [ 0.0614655  -1.90755689 -1.92793177]
# [-1.99058105 -1.87637856  0.09686741]
# [-1.9957153   0.04758118 -1.92721297]
# [-1.99730166 -0.13469231 -1.20341532]
# [ 0.0614655  -1.90755689 -1.92793177]]
# 가장 큰 결정 함수의 인덱스:
# [1 0 2 1 1 0 1 2 1 1 2 0 0 0 0 1 2 1 1 2 0 2 0 2 2 2 2 2 0 0 0 0 1 0 0 2 1 0]
# 예측:
# [1 0 2 1 1 0 1 2 1 1 2 0 0 0 0 1 2 1 1 2 0 2 0 2 2 2 2 2 0 0 0 0 1 0 0 2 1 0]

print("가장 큰 예측 확률의 인덱스:\n", np.argmax(gbrt.predict_proba(X_test), axis=1))
print("예측:\n", gbrt.predict(X_test))

# 가장 큰 예측 확률의 인덱스:
# [1 0 2 1 1 0 1 2 1 1 2 0 0 0 0 1 2 1 1 2 0 2 0 2 2 2 2 2 0 0 0 0 1 0 0 2 1 0]
# 예측:
# [1 0 2 1 1 0 1 2 1 1 2 0 0 0 0 1 2 1 1 2 0 2 0 2 2 2 2 2 0 0 0 0 1 0 0 2 1 0]
```

- predict_proba, decision_function의 결과값은 항상 n_samples, n_classes의 형태로 나타남
  - 이진 분류에서 decision_function에서는 예외적으로 양성 클래스인 classes_[1]에 대응하는 값을 가짐

```python
from sklearn.linear_model import LogisticRegression

logreg = LogisticRegression()

named_target = iris.target_names[y_train]
logreg.fit(X_train, named_target)
print("훈련 데이터에 있는 클래스 종류:", logreg.classes_)
print("예측:", logreg.predict(X_test)[:10])
argmax_dec_func = np.argmax(logreg.decision_function(X_test), axis=1)
print("가장 큰 결정 함수의 인덱스", argmax_dec_func[:10])
print("인덱스를 classes_에 연결:", logreg.classes_[argmax_dec_func][:10])

# 훈련 데이터에 있는 클래스 종류: ['setosa' 'versicolor' 'virginica']
# 예측: ['versicolor' 'setosa' 'virginica' 'versicolor' 'versicolor' 'setosa' 'versicolor' 'virginica' 'versicolor' 'versicolor']
# 가장 큰 결정 함수의 인덱스 [1 0 2 1 1 0 1 2 1 1]
# 인덱스를 classes_에 연결: ['versicolor' 'setosa' 'virginica' 'versicolor' 'versicolor' 'setosa' 'versicolor' 'virginica' 'versicolor' 'versicolor']
```

class가 항상 연속적인 정수형이 아닐 수 있으므로 분류기의 classes_ 속성을 이용해 실제 클래스의 이름을 얻음