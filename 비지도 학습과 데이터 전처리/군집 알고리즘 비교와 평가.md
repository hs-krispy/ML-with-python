## 군집 알고리즘 비교와 평가

#### 타깃값으로 군집 평가

- 군집 알고리즘의 결과를 실제 정답 클러스터와 비교해서 평가
  - 1(최적일 때), 0(무작위로 분류될 때) 사이의 값을 제공하는 ARI와 NMI (ARI는 음수가 될 수 있음)

```python
import matplotlib.pyplot as plt
import numpy as np
import mglearn
from sklearn.metrics.cluster import adjusted_rand_score
from sklearn.datasets import make_moons
from sklearn.preprocessing import StandardScaler
from sklearn.cluster import KMeans, AgglomerativeClustering, DBSCAN

X, y = make_moons(n_samples=200, noise=0.05, random_state=0)

scaler = StandardScaler()
X_scaled = scaler.fit_transform(X)

fig, axes = plt.subplots(1, 4, figsize=(15, 3), subplot_kw={'xticks':  (), 'yticks': ()})

algorithms = [KMeans(n_clusters=2), AgglomerativeClustering(n_clusters=2), DBSCAN()]

# 무작위 클러스터
random_clusters = np.random.RandomState(seed=0).randint(0, 2, len(X))

plt.rc('font', family="Malgun Gothic")
axes[0].scatter(X_scaled[:, 0], X_scaled[:, 1], c=random_clusters, cmap=mglearn.cm3, s=60, edgecolors="black")
axes[0].set_title("무작위 할당 - ARI: {:.2f}".format(adjusted_rand_score(y, random_clusters)))

for ax, algorithm in zip(axes[1:], algorithms):
    clusters = algorithm.fit_predict(X_scaled)
    ax.scatter(X_scaled[:, 0], X_scaled[:, 1], c=clusters, cmap=mglearn.cm3, s=60, edgecolors="black")
    ax.set_title("{} - ARI: {:.2f}".format(algorithm.__class__.__name__, adjusted_rand_score(y, clusters)))
```

<img src="https://user-images.githubusercontent.com/58063806/112324640-5a507d80-8cf6-11eb-87be-36044731f740.png" width=100% />

#### 타깃값 없이 군집 평가

- 군집 알고리즘을 적용할 때 보통은 그 결과와 비교할 타깃값이 없음
  - 그러므로 ARI, NMI 같은 지표는 성능 평가가 아니라 알고리즘을 개발할때나 도움
- 타깃값이 필요 없는 군집용 지표로는 **실루엣 계수**가 있음

> **실루엣 점수는 클러스터의 밀집 정도를 계산하는 것**으로 높을수록 좋으며 1이 최댓값 (하지만 모양이 복합할 때는 밀집도를 활용한 평가가 잘 동작하지 않음)

```python
import matplotlib.pyplot as plt
import numpy as np
import mglearn
from sklearn.metrics.cluster import silhouette_score
from sklearn.datasets import make_moons
from sklearn.preprocessing import StandardScaler
from sklearn.cluster import KMeans, AgglomerativeClustering, DBSCAN

X, y = make_moons(n_samples=200, noise=0.05, random_state=0)

scaler = StandardScaler()
X_scaled = scaler.fit_transform(X)

fig, axes = plt.subplots(1, 4, figsize=(15, 3), subplot_kw={'xticks':  (), 'yticks': ()})

algorithms = [KMeans(n_clusters=2), AgglomerativeClustering(n_clusters=2), DBSCAN()]

# 무작위 클러스터
random_clusters = np.random.RandomState(seed=0).randint(0, 2, len(X))

plt.rc('font', family="Malgun Gothic")
axes[0].scatter(X_scaled[:, 0], X_scaled[:, 1], c=random_clusters, cmap=mglearn.cm3, s=60, edgecolors="black")
axes[0].set_title("무작위 할당 : {:.2f}".format(silhouette_score(X_scaled, random_clusters)))

for ax, algorithm in zip(axes[1:], algorithms):
    clusters = algorithm.fit_predict(X_scaled)
    ax.scatter(X_scaled[:, 0], X_scaled[:, 1], c=clusters, cmap=mglearn.cm3, s=60, edgecolors="black")
    ax.set_title("{} : {:.2f}".format(algorithm.__class__.__name__, silhouette_score(X_scaled, clusters)))
```

<img src="https://user-images.githubusercontent.com/58063806/112326275-bbc51c00-8cf7-11eb-9bf1-bca678a4f0b2.png" width=100% />

실제로 DBSCAN의 결과가 가장 좋지만 점수는 낮은 것을 볼  수 있음

- 클러스터 평가에 더 적합한 전략은 견고성 기반의 지표
- 데이터에 잡음 포인트를 추가하거나 여러 가지 매개변수 설정으로 알고리즘을 실행하고 그 결과를 비교했을 때 결과가 일정하다면 신뢰할만한 결과로 볼 수 있음